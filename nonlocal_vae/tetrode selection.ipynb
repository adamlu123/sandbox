{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np_utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5daa7e856416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdecoding_data_spike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspike_data_binned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoding_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdecoding_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdecoding_data_lfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlfp_data_sampled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoding_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdecoding_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdecoding_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np_utils' is not defined"
     ]
    }
   ],
   "source": [
    "rat_name = 'SuperChris'\n",
    "data_dir = '/extra/yadongl10/data/rat_odor/Processed/'\n",
    "spike_data_binned = np.load(data_dir + rat_name + '/{}_spike_data_binned.npy'.format(rat_name.lower()))\n",
    "lfp_data_sampled = np.load(data_dir + rat_name + '/{}_lfp_data_sampled.npy'.format(rat_name.lower()))\n",
    "lfp_data_sampled = np.swapaxes(lfp_data_sampled, 1, 2)\n",
    "trial_info = np.load(data_dir + rat_name + '/{}_trial_info.npy'.format(rat_name.lower()))\n",
    "# process data\n",
    "trial_indices = filter_trials(trial_info)\n",
    "decoding_start = 210\n",
    "decoding_end = decoding_start + 25\n",
    "# scale data first\n",
    "spike_data_binned = spike_data_binned[trial_indices, :, :]\n",
    "spike_data_binned = (spike_data_binned - np.mean(spike_data_binned)) / np.std(spike_data_binned)\n",
    "lfp_data_sampled = lfp_data_sampled[trial_indices, :, :]\n",
    "decoding_data_spike = spike_data_binned[:, :, decoding_start:decoding_end]\n",
    "decoding_data_lfp = lfp_data_sampled[:, :, decoding_start:decoding_end]\n",
    "decoding_target = np_utils.to_categorical((trial_info[trial_indices, 3] - 1).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 0, 0, 0, 1, 2, 3, 0, 1, 0, 1, 2, 0, 1, 0, 0, 1, 3, 0, 1,\n",
       "       2, 3, 0, 1, 3, 0, 1, 0, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2,\n",
       "       0, 1, 0, 1, 3, 0, 0, 2, 3, 0, 2, 3, 0, 0, 0, 1, 2, 3, 0, 1, 2, 3, 0,\n",
       "       1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 2, 3, 0, 0, 1, 2, 3, 0, 1, 3, 0,\n",
       "       1, 2, 3, 0, 0, 1, 2, 3, 0, 2, 3, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2,\n",
       "       0, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 3, 0, 1, 2, 0,\n",
       "       1, 2, 0, 1, 2, 3, 0, 0, 1, 2, 3, 0, 2, 3, 0, 2, 3, 0, 1, 3, 0, 1, 2,\n",
       "       3, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trial_info[trial_indices, 3] - 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def filter_trials(trial_info):\n",
    "    rat_correct = trial_info[:, 0] == 1\n",
    "    in_sequence = trial_info[:, 1] == 1\n",
    "    not_odor_e = trial_info[:, 3] < 5\n",
    "    select = rat_correct & in_sequence & not_odor_e\n",
    "    return select\n",
    "\n",
    "\n",
    "def prepare_data(rat_name = 'SuperChris'):\n",
    "    # load data\n",
    "    data_dir = '/extra/yadongl10/data/rat_odor/Processed/'\n",
    "    spike_data_binned = np.load(data_dir + rat_name + '/{}_spike_data_binned.npy'.format(rat_name.lower()))\n",
    "    lfp_data_sampled = np.load(data_dir + rat_name + '/{}_lfp_data_sampled.npy'.format(rat_name.lower()))\n",
    "    lfp_data_sampled = np.swapaxes(lfp_data_sampled, 1, 2)\n",
    "    trial_info = np.load(data_dir + rat_name + '/{}_trial_info.npy'.format(rat_name.lower()))\n",
    "    # process data\n",
    "    trial_indices = filter_trials(trial_info)\n",
    "    decoding_start = 210\n",
    "    decoding_end = decoding_start + 25\n",
    "    # scale data first\n",
    "    spike_data_binned = spike_data_binned[trial_indices, :, :]\n",
    "    spike_data_binned = (spike_data_binned - np.mean(spike_data_binned)) / np.std(spike_data_binned)\n",
    "    lfp_data_sampled = lfp_data_sampled[trial_indices, :, :]\n",
    "    decoding_data_spike = spike_data_binned[:, :, decoding_start:decoding_end]\n",
    "    decoding_data_lfp = lfp_data_sampled[:, :, decoding_start:decoding_end]\n",
    "    decoding_target = (trial_info[trial_indices, 3] - 1).astype(int) # np_utils.to_categorical()\n",
    "    # organize tetrode data\n",
    "    if rat_name.lower() == 'superchris':\n",
    "        tetrode_ids = [1, 10, 12, 13, 14, 15, 16, 18, 19, 2, 20, 21, 22, 23, 3, 4, 5, 6, 7, 8, 9]\n",
    "        tetrode_units = {1:3, 10:0, 12:1, 13:8, 14:4, 15:6, 16:1, 18:0, 19:4, 2:3,\n",
    "                         20:0, 21:1, 22:5, 23:7, 3:0, 4:0, 5:0, 6:0, 7:1, 8:1, 9:1}\n",
    "    elif rat_name.lower() == 'stella':\n",
    "        tetrode_ids = [10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        tetrode_units = {10:1, 12:0, 13:5, 14:7, 15:4, 16:8, 17:0, 18:0, 19:1, 20:0,\n",
    "                     21:1, 22:1, 23:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:13, 8:4, 9:4}\n",
    "    elif rat_name.lower() == 'buchanan':\n",
    "        tetrode_ids = [10, 12, 13, 15, 16, 17, 18, 19, 1, 20, 21, 22, 23, 2, 4, 5, 6, 7, 8, 9]\n",
    "        tetrode_units = {10:0, 12:0, 13:9, 15:6, 16:0, 17:4, 18:12, 19:15, 1:0,\n",
    "                     20:0, 21:1, 22:13, 23:8, 2:2, 4:0, 5:6, 6:3, 7:0, 8:0, 9:0}\n",
    "    elif rat_name.lower() == 'barat':\n",
    "        tetrode_ids = [10, 12, 13, 14, 15, 16, 17, 18, 19, 1, 20, 21, 22, 23, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        tetrode_units = {10:1, 12:20, 13:12, 14:7, 15:0, 16:0, 17:11, 18:0, 19:0, 1:1, 20:0, 21:9, 22:0,\n",
    "                         23:1, 2:0, 3:11, 4:0, 5:4, 6:0, 7:1, 8:0, 9:14}\n",
    "    elif rat_name.lower() == 'mitt':\n",
    "        tetrode_ids = [12, 13, 14, 15, 16, 17, 18, 19, 1, 20, 21, 22, 23, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "        tetrode_units = {12:16, 13:15, 14:4, 15:2, 16:6, 17:2, 18:12, 19:15, 1:0, 20:12, 21:0, 22:1,\n",
    "                         23:4, 2:0, 3:4, 4:0, 5:0, 6:0, 7:3, 8:1, 9:7}\n",
    "    tetrode_data = organize_tetrode(decoding_data_spike, decoding_data_lfp, tetrode_ids, tetrode_units)\n",
    "    return tetrode_data, decoding_target, tetrode_ids, tetrode_units, spike_data_binned, lfp_data_sampled\n",
    "\n",
    "\n",
    "def stack_data(all_d