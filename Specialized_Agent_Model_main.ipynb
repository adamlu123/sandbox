{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Specialized Neural Network Agents to Identify Invalid Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook train 5 separate specialized agents for detecting each of the rule violated (in total there are 5 rules). Each character in the keys are transformed to one hot vector before feeding into the neural network model through a process called tokenize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yadongl1/anaconda3/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf\n",
    "CONFIG = tf.ConfigProto(device_count = {'GPU': 1}, log_device_placement=False, allow_soft_placement=False)\n",
    "CONFIG.gpu_options.allow_growth = True # Prevents tf from grabbing all gpu memory.\n",
    "sess = tf.Session(config=CONFIG)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "\n",
    "import h5py\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import time\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam,RMSprop\n",
    "from keras.layers import Input, Dense, Flatten, Reshape, merge, Activation,Dropout,concatenate,Lambda\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import gen_v2\n",
    "import imp\n",
    "imp.reload(gen_v2)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_chars = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890\"\n",
    "tokenizer = Tokenizer(num_words=38) \n",
    "tokenizer.fit_on_texts(list(_chars))\n",
    "print(len(list(_chars)))\n",
    "# tokenizer.texts_to_sequences(_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing rule 1\n",
      "<function r1 at 0x2b895b36e158> <function not_r1 at 0x2b895b30f7b8>\n",
      "preparing rule 2\n",
      "<function r2 at 0x2b895b30fbf8> <function not_r2 at 0x2b895b30f6a8>\n",
      "preparing rule 3\n",
      "<function r3 at 0x2b895b30f730> <function not_r3 at 0x2b895b30f8c8>\n",
      "preparing rule 4\n",
      "<function r4 at 0x2b895b30f598> <function not_r4 at 0x2b895b30f840>\n",
      "preparing rule 5\n",
      "<function r5 at 0x2b895b30ff28> <function not_r5 at 0x2b895b01cb70>\n"
     ]
    }
   ],
   "source": [
    "def prepare_data( n , rule_broken = 'r1'):\n",
    "    \"\"\"\n",
    "    Prepare the data consists of half valid keys and half invalid keys with one rule broken. \n",
    "    \"\"\"\n",
    "    string_list = []\n",
    "    r1_func = getattr(gen_v2, rule_broken)\n",
    "    not_r1_func = getattr(gen_v2, 'not_'+rule_broken)\n",
    "    print(r1_func, not_r1_func)\n",
    "    for i in range(n):\n",
    "        seq = gen_v2.random_char_seq()\n",
    "        seq = r1_func(seq)\n",
    "        seq0 = gen_v2.random_char_seq()\n",
    "        seq0 = not_r1_func(seq0)\n",
    "        string_list.append( seq + ', ' + str(1) )\n",
    "        string_list.append( seq0 + ', ' + str(0) )\n",
    "    random.shuffle(string_list)\n",
    "    return string_list\n",
    "\n",
    "def prepare_x_y_train():\n",
    "    \"\"\"\n",
    "    wrap string data into h5 file; \n",
    "    use keras tokonizer to transform each character into one hot encoded vector.\n",
    "    \"\"\"\n",
    "    for i in range(1, 6):\n",
    "        print('preparing rule {}'.format(i))\n",
    "        string_list = prepare_data( n=100000, rule_broken = 'r'+str(i) )\n",
    "        texts_into_letters = []\n",
    "        label = []\n",
    "        for j,letter in enumerate(string_list):\n",
    "            texts_into_letters.append( list(string_list[j])[:36] )\n",
    "            label.append( float( list(string_list[j])[38] ) )  # 38th is the label 1 or 0\n",
    "        # print(texts_into_letters)    \n",
    "        _chars = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890\"\n",
    "        tokenizer = Tokenizer(num_words=38) # most frequent 100 words, set it to be large to include all possible words \n",
    "#         tokenizer.fit_on_texts(texts_into_letters)\n",
    "        tokenizer.fit_on_texts(_chars)\n",
    "        sequences_list = tokenizer.texts_to_sequences(texts_into_letters)\n",
    "        sequences = np.asarray( [np.asarray(x) for x in sequences_list] )\n",
    "        # print(sequences.shape)\n",
    "        cat_sequences = keras.utils.to_categorical(sequences, num_classes=None)[:,:,1:] # the tokenizer starts from 1\n",
    "        with h5py.File( \"/extra/yadongl10/keys/data/r{}.h5\".format(i), \"w\" ) as f:\n",
    "            f.create_dataset('text', data=cat_sequences)\n",
    "            f.create_dataset('label', data=label)\n",
    "            \n",
    "prepare_x_y_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from: /extra/yadongl10/keys/data/r1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yadongl1/anaconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 36, 36)            0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 64)                83008     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 95,553\n",
      "Trainable params: 95,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "160000/160000 [==============================] - 22s 138us/step - loss: 0.0193 - acc: 0.9899 - val_loss: 5.2648e-06 - val_acc: 1.0000\n",
      "Epoch 2/15\n",
      "160000/160000 [==============================] - 14s 89us/step - loss: 1.3636e-06 - acc: 1.0000 - val_loss: 7.2750e-07 - val_acc: 1.0000\n",
      "Epoch 3/15\n",
      "160000/160000 [==============================] - 14s 88us/step - loss: 2.9912e-07 - acc: 1.0000 - val_loss: 2.7729e-07 - val_acc: 1.0000\n",
      "Epoch 4/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.5170e-07 - acc: 1.0000 - val_loss: 1.5374e-07 - val_acc: 1.0000\n",
      "Epoch 5/15\n",
      "160000/160000 [==============================] - 13s 84us/step - loss: 1.1819e-07 - acc: 1.0000 - val_loss: 1.2108e-07 - val_acc: 1.0000\n",
      "Epoch 6/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 1.1114e-07 - acc: 1.0000 - val_loss: 1.1274e-07 - val_acc: 1.0000\n",
      "Epoch 7/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.0982e-07 - acc: 1.0000 - val_loss: 1.1066e-07 - val_acc: 1.0000\n",
      "Epoch 8/15\n",
      "160000/160000 [==============================] - 14s 90us/step - loss: 1.0963e-07 - acc: 1.0000 - val_loss: 1.1009e-07 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "160000/160000 [==============================] - 14s 87us/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.0998e-07 - val_acc: 1.0000\n",
      "Epoch 10/15\n",
      "160000/160000 [==============================] - 14s 88us/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.0996e-07 - val_acc: 1.0000\n",
      "Epoch 11/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.0988e-07 - val_acc: 1.0000\n",
      "Epoch 12/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.0990e-07 - val_acc: 1.0000\n",
      "Epoch 13/15\n",
      "160000/160000 [==============================] - 13s 83us/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.0981e-07 - val_acc: 1.0000\n",
      "Epoch 14/15\n",
      "160000/160000 [==============================] - 13s 82us/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.0972e-07 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.0970e-07 - val_acc: 1.0000\n",
      "loading data from: /extra/yadongl10/keys/data/r2.h5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 36, 36)            0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 64)                83008     \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 95,553\n",
      "Trainable params: 95,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "160000/160000 [==============================] - 16s 100us/step - loss: 0.0203 - acc: 0.9891 - val_loss: 2.9818e-06 - val_acc: 1.0000\n",
      "Epoch 2/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.2513e-06 - acc: 1.0000 - val_loss: 6.7536e-07 - val_acc: 1.0000\n",
      "Epoch 3/15\n",
      "160000/160000 [==============================] - 14s 87us/step - loss: 3.1656e-07 - acc: 1.0000 - val_loss: 2.3330e-07 - val_acc: 1.0000\n",
      "Epoch 4/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.4927e-07 - acc: 1.0000 - val_loss: 1.3872e-07 - val_acc: 1.0000\n",
      "Epoch 5/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.1698e-07 - acc: 1.0000 - val_loss: 1.1676e-07 - val_acc: 1.0000\n",
      "Epoch 6/15\n",
      "160000/160000 [==============================] - 13s 84us/step - loss: 1.1084e-07 - acc: 1.0000 - val_loss: 1.1177e-07 - val_acc: 1.0000\n",
      "Epoch 7/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 1.0978e-07 - acc: 1.0000 - val_loss: 1.1033e-07 - val_acc: 1.0000\n",
      "Epoch 8/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 1.0963e-07 - acc: 1.0000 - val_loss: 1.1020e-07 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "160000/160000 [==============================] - 14s 90us/step - loss: 1.0961e-07 - acc: 1.0000 - val_loss: 1.1004e-07 - val_acc: 1.0000\n",
      "Epoch 10/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.0961e-07 - acc: 1.0000 - val_loss: 1.1014e-07 - val_acc: 1.0000\n",
      "Epoch 11/15\n",
      "160000/160000 [==============================] - 14s 89us/step - loss: 1.0961e-07 - acc: 1.0000 - val_loss: 1.1006e-07 - val_acc: 1.0000\n",
      "Epoch 12/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.0961e-07 - acc: 1.0000 - val_loss: 1.0985e-07 - val_acc: 1.0000\n",
      "Epoch 13/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.0961e-07 - acc: 1.0000 - val_loss: 1.0962e-07 - val_acc: 1.0000\n",
      "Epoch 14/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 1.0961e-07 - acc: 1.0000 - val_loss: 1.0962e-07 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 1.0961e-07 - acc: 1.0000 - val_loss: 1.0962e-07 - val_acc: 1.0000\n",
      "loading data from: /extra/yadongl10/keys/data/r3.h5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 36, 36)            0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 64)                83008     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 95,553\n",
      "Trainable params: 95,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "160000/160000 [==============================] - 17s 108us/step - loss: 0.0213 - acc: 0.9913 - val_loss: 0.0029 - val_acc: 0.9988\n",
      "Epoch 2/15\n",
      "160000/160000 [==============================] - 15s 94us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0025 - val_acc: 0.9993\n",
      "Epoch 3/15\n",
      "160000/160000 [==============================] - 14s 89us/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.0022 - val_acc: 0.9993\n",
      "Epoch 4/15\n",
      "160000/160000 [==============================] - 14s 88us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0013 - val_acc: 0.9997\n",
      "Epoch 5/15\n",
      "160000/160000 [==============================] - 14s 87us/step - loss: 7.6118e-04 - acc: 0.9998 - val_loss: 0.0012 - val_acc: 0.9997\n",
      "Epoch 6/15\n",
      "160000/160000 [==============================] - 14s 87us/step - loss: 7.7726e-04 - acc: 0.9997 - val_loss: 0.0028 - val_acc: 0.9993\n",
      "Epoch 7/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 7.4203e-04 - acc: 0.9998 - val_loss: 0.0014 - val_acc: 0.9996\n",
      "Epoch 8/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 3.7863e-04 - acc: 0.9999 - val_loss: 0.0022 - val_acc: 0.9997\n",
      "Epoch 9/15\n",
      "160000/160000 [==============================] - 14s 89us/step - loss: 1.9507e-04 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9992\n",
      "Epoch 10/15\n",
      "160000/160000 [==============================] - 15s 93us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0023 - val_acc: 0.9994\n",
      "Epoch 11/15\n",
      "160000/160000 [==============================] - 14s 87us/step - loss: 2.8434e-04 - acc: 0.9999 - val_loss: 0.0017 - val_acc: 0.9996\n",
      "Epoch 12/15\n",
      "160000/160000 [==============================] - 14s 90us/step - loss: 2.6144e-04 - acc: 0.9999 - val_loss: 0.0013 - val_acc: 0.9995\n",
      "Epoch 13/15\n",
      "160000/160000 [==============================] - 14s 87us/step - loss: 2.7011e-04 - acc: 0.9999 - val_loss: 0.0027 - val_acc: 0.9993\n",
      "Epoch 14/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 2.2924e-04 - acc: 0.9999 - val_loss: 0.0070 - val_acc: 0.9987\n",
      "Epoch 15/15\n",
      "160000/160000 [==============================] - 13s 82us/step - loss: 1.4750e-04 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9996\n",
      "loading data from: /extra/yadongl10/keys/data/r4.h5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 36, 36)            0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 64)                83008     \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 95,553\n",
      "Trainable params: 95,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "160000/160000 [==============================] - 16s 101us/step - loss: 0.0224 - acc: 0.9887 - val_loss: 2.4019e-04 - val_acc: 0.9999\n",
      "Epoch 2/15\n",
      "160000/160000 [==============================] - 15s 93us/step - loss: 0.0019 - acc: 0.9993 - val_loss: 2.5816e-04 - val_acc: 1.0000\n",
      "Epoch 3/15\n",
      "160000/160000 [==============================] - 15s 95us/step - loss: 8.8980e-04 - acc: 0.9998 - val_loss: 0.0031 - val_acc: 0.9990\n",
      "Epoch 4/15\n",
      "160000/160000 [==============================] - 14s 90us/step - loss: 3.6134e-04 - acc: 0.9999 - val_loss: 8.1867e-05 - val_acc: 1.0000\n",
      "Epoch 5/15\n",
      "160000/160000 [==============================] - 14s 87us/step - loss: 2.5569e-04 - acc: 0.9999 - val_loss: 4.9227e-04 - val_acc: 0.9998\n",
      "Epoch 6/15\n",
      "160000/160000 [==============================] - 13s 83us/step - loss: 4.2638e-04 - acc: 0.9999 - val_loss: 2.3986e-04 - val_acc: 0.9999\n",
      "Epoch 7/15\n",
      "160000/160000 [==============================] - 13s 80us/step - loss: 1.2955e-04 - acc: 1.0000 - val_loss: 3.7853e-05 - val_acc: 1.0000\n",
      "Epoch 8/15\n",
      "160000/160000 [==============================] - 13s 79us/step - loss: 1.5250e-04 - acc: 0.9999 - val_loss: 9.4251e-07 - val_acc: 1.0000\n",
      "Epoch 9/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 6.7266e-07 - acc: 1.0000 - val_loss: 1.4759e-07 - val_acc: 1.0000\n",
      "Epoch 10/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 1.4031e-07 - acc: 1.0000 - val_loss: 8.4771e-06 - val_acc: 1.0000\n",
      "Epoch 11/15\n",
      "160000/160000 [==============================] - 14s 89us/step - loss: 1.1128e-07 - acc: 1.0000 - val_loss: 3.0544e-07 - val_acc: 1.0000\n",
      "Epoch 12/15\n",
      "160000/160000 [==============================] - 14s 88us/step - loss: 1.0970e-07 - acc: 1.0000 - val_loss: 2.4940e-07 - val_acc: 1.0000\n",
      "Epoch 13/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.0964e-07 - acc: 1.0000 - val_loss: 2.0722e-07 - val_acc: 1.0000\n",
      "Epoch 14/15\n",
      "160000/160000 [==============================] - 14s 86us/step - loss: 1.0961e-07 - acc: 1.0000 - val_loss: 1.7489e-07 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "160000/160000 [==============================] - 13s 81us/step - loss: 1.0960e-07 - acc: 1.0000 - val_loss: 1.5645e-07 - val_acc: 1.0000\n",
      "loading data from: /extra/yadongl10/keys/data/r5.h5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 36, 36)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1296)              0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 64)                83008     \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 95,553\n",
      "Trainable params: 95,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 160000 samples, validate on 40000 samples\n",
      "Epoch 1/15\n",
      "160000/160000 [==============================] - 16s 98us/step - loss: 0.4146 - acc: 0.7545 - val_loss: 0.1024 - val_acc: 0.9711\n",
      "Epoch 2/15\n",
      "160000/160000 [==============================] - 15s 92us/step - loss: 0.0784 - acc: 0.9794 - val_loss: 0.0792 - val_acc: 0.9809\n",
      "Epoch 3/15\n",
      "160000/160000 [==============================] - 17s 106us/step - loss: 0.0652 - acc: 0.9826 - val_loss: 0.0786 - val_acc: 0.9811\n",
      "Epoch 4/15\n",
      "160000/160000 [==============================] - 16s 98us/step - loss: 0.0537 - acc: 0.9851 - val_loss: 0.0804 - val_acc: 0.9811\n",
      "Epoch 5/15\n",
      "160000/160000 [==============================] - 16s 98us/step - loss: 0.0415 - acc: 0.9877 - val_loss: 0.0906 - val_acc: 0.9799\n",
      "Epoch 6/15\n",
      "160000/160000 [==============================] - 15s 92us/step - loss: 0.0308 - acc: 0.9902 - val_loss: 0.1043 - val_acc: 0.9790\n",
      "Epoch 7/15\n",
      "160000/160000 [==============================] - 15s 91us/step - loss: 0.0214 - acc: 0.9928 - val_loss: 0.1253 - val_acc: 0.9781\n",
      "Epoch 8/15\n",
      "160000/160000 [==============================] - 15s 91us/step - loss: 0.0164 - acc: 0.9943 - val_loss: 0.1322 - val_acc: 0.9769\n",
      "Epoch 9/15\n",
      "160000/160000 [==============================] - 14s 90us/step - loss: 0.0136 - acc: 0.9956 - val_loss: 0.1374 - val_acc: 0.9767\n",
      "Epoch 10/15\n",
      "160000/160000 [==============================] - 15s 92us/step - loss: 0.0110 - acc: 0.9962 - val_loss: 0.1472 - val_acc: 0.9758\n",
      "Epoch 11/15\n",
      "160000/160000 [==============================] - 15s 96us/step - loss: 0.0105 - acc: 0.9964 - val_loss: 0.1673 - val_acc: 0.9770\n",
      "Epoch 12/15\n",
      "160000/160000 [==============================] - 15s 91us/step - loss: 0.0086 - acc: 0.9970 - val_loss: 0.1562 - val_acc: 0.9750\n",
      "Epoch 13/15\n",
      "160000/160000 [==============================] - 15s 92us/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.1774 - val_acc: 0.9794\n",
      "Epoch 14/15\n",
      "160000/160000 [==============================] - 14s 85us/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.1826 - val_acc: 0.9786\n",
      "Epoch 15/15\n",
      "160000/160000 [==============================] - 14s 89us/step - loss: 0.0070 - acc: 0.9976 - val_loss: 0.1813 - val_acc: 0.9794\n"
     ]
    }
   ],
   "source": [
    "hp = {\n",
    "    'dimension' : 64,\n",
    "    'n_layer' : 4,\n",
    "    'init' : 'he_normal',\n",
    "    'act' : 'relu'\n",
    "}\n",
    "hp\n",
    "\n",
    "def build_model(hp):\n",
    "    input_text = Input(shape=(36,36,))\n",
    "    dimensions = [hp['dimension']]* hp['n_layer']\n",
    "    init = hp['init']\n",
    "    act = hp['act']\n",
    "\n",
    "    x= Flatten()(input_text)\n",
    "    for i in dimensions:\n",
    "        x = Dense(i,init = init, activation=act)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_text, outputs=output)\n",
    "\n",
    "    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    model.compile(loss= 'binary_crossentropy', # contrastive_loss, #\n",
    "                  optimizer=  optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "\n",
    "def run_experiment(hp):\n",
    "    # prepare data\n",
    "    model_list = []\n",
    "    for i in ['r1', 'r2', 'r3', 'r4', 'r5']:\n",
    "        print('loading data from: /extra/yadongl10/keys/data/{}.h5'.format(i))\n",
    "        with h5py.File('/extra/yadongl10/keys/data/{}.h5'.format(i), 'r') as f:\n",
    "            cat_sequences_combine_shuffle = np.asarray( f['text'] )\n",
    "            label_seq_combine_shuffle = np.asarray(f['label'])\n",
    "            \n",
    "        model = build_model(hp)\n",
    "        cut = int( 0.8 * cat_sequences_combine_shuffle.shape[0] )\n",
    "        model.fit(cat_sequences_combine_shuffle[:cut,:,:], label_seq_combine_shuffle[:cut],\\\n",
    "          batch_size=64, epochs=15, validation_data=(cat_sequences_combine_shuffle[cut:,:,:],\\\n",
    "                           label_seq_combine_shuffle[cut:]))\n",
    "        model_list.append(model)\n",
    "    return model_list\n",
    "model_list = run_experiment(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from: /extra/yadongl10/keys/data/r1.h5\n"
     ]
    }
   ],
   "source": [
    "for i in ['r1']:\n",
    "    print('loading data from: /extra/yadongl10/keys/data/{}.h5'.format(i))\n",
    "    with h5py.File('/extra/yadongl10/keys/data/{}.h5'.format(i), 'r') as f:\n",
    "        cat_sequences_combine_shuffle = np.asarray( f['text'] )\n",
    "        label_seq_combine_shuffle = np.asarray( f['label'] )\n",
    "    md0_r2_pred = model_list[0].predict(cat_sequences_combine_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00]\n",
      " [2.2854624e-23]\n",
      " [3.1014217e-19]\n",
      " ...\n",
      " [1.0000000e+00]\n",
      " [1.0000000e+00]\n",
      " [1.0000000e+00]] [1. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(md0_r2_pred,label_seq_combine_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print('saving model',i)\n",
    "    model_list[i].save('/extra/yadongl10/keys/trained_model/md_for_rule_{}.h5'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(10000, 36, 36)\n",
      "1\n",
      "(10000, 36, 36)\n",
      "2\n",
      "(10000, 36, 36)\n",
      "3\n",
      "(10000, 36, 36)\n",
      "4\n",
      "(10000, 36, 36)\n"
     ]
    }
   ],
   "source": [
    "def texts_to_cat(texts_valid):\n",
    "    texts_into_letters = []\n",
    "    for i,letter in enumerate(texts_valid):\n",
    "        assert len( list(texts_valid.iloc[i]) ) == 36\n",
    "        texts_into_letters.append(list(texts_valid.iloc[i]))\n",
    "    texts_valid = texts_into_letters \n",
    "    \n",
    "    _chars = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890\"\n",
    "    tokenizer = Tokenizer(num_words=37) # most frequent 100 words, set it to be large to include all possible words \n",
    "    tokenizer.fit_on_texts(_chars)\n",
    "    sequences_valid_list = tokenizer.texts_to_sequences(texts_valid)\n",
    "    \n",
    "    sequences_valid = np.asarray( [np.asarray(x) for x in sequences_valid_list] )\n",
    "    cat_sequences_valid = keras.utils.to_categorical(sequences_valid, num_classes=None)[:,:,1:]\n",
    "    print(cat_sequences_valid.shape)\n",
    "    return cat_sequences_valid\n",
    "\n",
    "pred_list = []\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    valid = pd.read_table(  '/extra/yadongl10/keys/invalid.txt',sep=',' ,header=None)\n",
    "#     texts_to_cat(valid.iloc[:,0]) \n",
    "    cat_sequences_combine_shuffle = texts_to_cat(valid.iloc[:,0])\n",
    "    pred = model_list[i].predict(cat_sequences_combine_shuffle) \n",
    "    pred[pred<0.5] = 0\n",
    "    pred[pred>0.5] = 1\n",
    "    pred_list.append( pred )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(2000, 36, 36)\n",
      "2\n",
      "(2000, 36, 36)\n",
      "3\n",
      "(2000, 36, 36)\n",
      "4\n",
      "(2000, 36, 36)\n",
      "5\n",
      "(2000, 36, 36)\n",
      "[1984.]\n",
      "[1987.]\n",
      "[1988.]\n",
      "[1987.]\n",
      "[10.]\n"
     ]
    }
   ],
   "source": [
    "def pred_on_r1_to_r5(model):\n",
    "    \"\"\"\n",
    "    Use a specialized model to predict on r1,r2,r3,r4,r5 and print the predicted number of valid keys\n",
    "    Ideally, specialized model for ri should predict very few number of valid when rule i are violated. \n",
    "    \"\"\"\n",
    "    pred_list=[]\n",
    "    for i in range(1,6):\n",
    "        print(i)\n",
    "        valid = pd.read_table( '/extra/yadongl10/keys/invalid_keys_single_char/r{}.txt'.format(i),sep=',' ,header=None)\n",
    "#         texts_to_cat(valid.iloc[:,0]) \n",
    "        cat_sequences_combine_shuffle = texts_to_cat(valid.iloc[:,0])\n",
    "        pred = model.predict(cat_sequences_combine_shuffle) \n",
    "        pred[pred<0.5] = 0\n",
    "        pred[pred>0.5] = 1\n",
    "        pred_list.append( pred )\n",
    "    # Model 0 predicts on r1 to r5.txt\n",
    "    for i in range(5):\n",
    "        print(sum(pred_list[i]))\n",
    "        \n",
    "pred_on_r1_to_r5(model_list[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
